{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import sys, os, json, pdb\n",
      "import pprint as pp\n",
      "import datetime as dt\n",
      "import itertools\n",
      "from collections import defaultdict\n",
      "import networkx as nx\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy\n",
      "import numpy as np\n",
      "\n",
      "paper_author = defaultdict(list)\n",
      "cited_by = defaultdict(list)\n",
      "\n",
      "# convert input json to defaultdicts\n",
      "source_cited = json.load(open('out/sundayrun/GSE1456_cited_by.json', 'r'))\n",
      "for k in source_cited:\n",
      "    cited_by[k] = source_cited[k]\n",
      "source_authors = json.load(open('out/sundayrun/GSE1456_paper_author.json', 'r'))\n",
      "for k in source_authors:\n",
      "    paper_author[k] = source_authors[k]\n",
      "GSE = json.load(open('first_gen.json', 'r'))\n",
      "\n",
      "author_paper = defaultdict(list)\n",
      "for paper, authors in paper_author.items():\n",
      "    for a in authors:\n",
      "        author_paper[a].append(paper)\n",
      "\n",
      "print 'loaded dictionaries...'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded dictionaries...\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### basic statistics\n",
      "paper_list = [item for sublist in cited_by.values() for item in sublist]\n",
      "paper_list.extend(cited_by.keys())\n",
      "paper_list = list(set(paper_list))\n",
      "author_list = list(set([item for sublist in paper_author.values() for item in sublist]))\n",
      "\n",
      "print 'degree 2 statistics:'\n",
      "print '\\t num paper_author keys', len(paper_author)\n",
      "print '\\t num papers', len(paper_list)\n",
      "print '\\t num authors', len(author_list)\n",
      "\n",
      "original = GSE['GSE1456'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "degree 2 statistics:\n",
        "\t num paper_author keys 3323\n",
        "\t num papers 3323\n",
        "\t num authors 19819\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### document citation network\n",
      "\n",
      "paper_node_key = dict((v,k) for k,v in dict(enumerate(paper_list)).items())\n",
      "\n",
      "\n",
      "G_D = nx.DiGraph()\n",
      "# create nodes\n",
      "for paper in paper_list:\n",
      "    if paper in original:\n",
      "        G_D.add_node(paper_node_key[paper], pmid=paper, is_original='yes')\n",
      "    else:\n",
      "        G_D.add_node(paper_node_key[paper], pmid=paper, is_original='no')\n",
      "\n",
      "# create directed citation edges\n",
      "for paper in cited_by:\n",
      "    for cited in cited_by[paper]:\n",
      "        G_D.add_edge(paper_node_key[paper], paper_node_key[cited])\n",
      "\n",
      "# nx.draw(G_D)\n",
      "# plt.show()\n",
      "\n",
      "# G_D.degree(original)\n",
      "# neighbors = nx.all_neighbors(G_D, original[0])\n",
      "\n",
      "### intra-class random walk on citation network"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from networkx.algorithms import bipartite\n",
      "### document-author bipartite graph \n",
      "\n",
      "G_AD = nx.Graph()\n",
      "G_AD.add_nodes_from(paper_author.keys(), bipartite='documents')\n",
      "G_AD.add_nodes_from(author_list, bipartite='authors')\n",
      "\n",
      "\n",
      "# key is author, for each author there is dict of counts of coauthor (for edge weights)\n",
      "coauthors = defaultdict(lambda : defaultdict(int))\n",
      "\n",
      "for paper, authors in paper_author.items():\n",
      "    # create bipartite edge between paper-author\n",
      "    for a in authors:\n",
      "        G_AD.add_edge(paper, a)\n",
      "    # make coauthor dictionary\n",
      "    auth_perm = list(itertools.permutations(authors,2))\n",
      "    for pair in auth_perm:\n",
      "        coauthors[pair[0]][pair[1]] += 1\n",
      "        \n",
      "print 'document-author bipartite graph created...'\n",
      "print 'coauthor dict created...'\n",
      "\n",
      "# nx.draw(G_AD)\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "document-author bipartite graph created...\n",
        "coauthor dict created...\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### author social network\n",
      "author_node_key = dict((v,k) for k,v in dict(enumerate(coauthors.keys())).items())\n",
      "\n",
      "G_A = nx.Graph()\n",
      "# G_A.add_nodes_from(author_list)\n",
      "# single_author_papers = list(set(author_list) - set(coauthors.keys()))\n",
      "G_A.add_nodes_from(author_node_key.keys())\n",
      "for author in coauthors:\n",
      "    for coauth in coauthors[author]:\n",
      "        G_A.add_edge(author_node_key[author], author_node_key[coauth], weight=coauthors[author][coauth])\n",
      "\n",
      "# nx.draw(G_A)\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows_A = []\n",
      "cols_A = []\n",
      "T = []\n",
      "for a1 in coauthors.keys():\n",
      "    for a2 in coauthors.keys():\n",
      "        T_ij = []\n",
      "        for paper in author_paper[a1]:\n",
      "            if (a1 != a2) and (a2 in paper_author[paper]):\n",
      "                e_k = len(paper_author[p])\n",
      "                denom = e_k * (e_k + 1) * 1.0 / 2\n",
      "                T_ij.append(1*1.0/denom)\n",
      "        rows_A.append(author_node_key[a1])\n",
      "        cols_A.append(author_node_key[a2])\n",
      "        T.append(sum(T_ij))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-87-2677f13eeda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mT_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpaper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mauthor_paper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaper_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0me_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_k\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me_k\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "[(0, u'Ruiz, Irune'),\n",
        " (1, u'Drapeau, Mark D'),\n",
        " (2, u'Stamenkovic, Ivan'),\n",
        " (3, u'Saini, Kamal'),\n",
        " (4, u'Hu, Wei'),\n",
        " (5, u'Mlecnik, Bernhard'),\n",
        " (6, u'Bromberg, Jacqueline'),\n",
        " (7, u'Saeed, Sadia'),\n",
        " (8, u'Guerra-Rebollo, Marta'),\n",
        " (9, u'Zhang, Kaitai')]"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_transition(graph_type):\n",
      "    if graph_type == 'document':\n",
      "        \n",
      "    \n",
      "    if graph_type == 'author':\n",
      "        \n",
      "        \n",
      "    return T\n",
      "\n",
      "def intra_walk(G, M, alpha):\n",
      "    n_M = len(G.nodes())\n",
      "    one = [1] * n_M\n",
      "    M_ = (1 - alpha)*M + (alpha*1.0/n_M) * one * one.T\n",
      "    return M_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}